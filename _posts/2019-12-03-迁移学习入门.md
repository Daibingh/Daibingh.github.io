---
layout: post
title:  "迁移学习入门"
categories: DL
tags: DL 迁移学习
author: hdb
comments: true
excerpt: "迁移学习常见的类型介绍。"
mathjax: true
---

* content
{:toc}


## 常见类型

总的来讲，迁移学习（Transfer Learning）是借鉴**不同领域的数据集相同任务**或**相同领域数据集不同任务**的模型到当前考虑的任务中，提升效果或加速学习过程。

- Model Fine-tuning
- Multi-task learning

## Model Fine-tuning

思想：通过源数据(source data)训练模型，然后通过目标数据(target data)微调模型，模型是一样的

<img src="/images/model-fine-tuning.png" width="500px">

## Layer Transfer

将 Model A 的部分层拷贝给 Model B，之后做 fine-tuning

<img src="/images/layer-transfer.png" width="500px">

## Multi-task learning

<img src="/images/multitask-learning.png" width="500px">

## Domain- adversarial training

条件：source data 是有标签的，target data 无标签

<img src="/images/domain-adversa-training-1.png" width="500px">

<img src="/images/domain-adversa-training-2.png" width="500px">

<img src="/images/domain-adversa-training-3.png" width="500px">

## Zero-shot learning

测试集中的图片代表的类别在训练集中没出现过，如何进行有效的预测或分类？

### Representing each class by its attributes

不直接学习类别分类，而是进行**属性表示学习**，对于新来类别的图片，虽然模型无法给出类别预测，但是可以作属性预测，根据属性我们可以用另外的方法获得类别，具体来讲可以做 Attribute embedding + word embedding

<img src="/images/zero-shot-learning.png" width="500px">

在上图中将 image 和 word 嵌入到同一个特征空间，通过 minimize 对应点之间的距离进行学习

### Convex Combination of Semantic Embedding

<img src="/images/zero-shot-learning-2.png" width="500px">

